{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as activation_functions\n",
    "from torch.utils.data import default_collate\n",
    "import torch.nn as neural_network\n",
    "import torch.optim as optimization\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vit_b_32, ViT_B_32_Weights\n",
    "from torch import nn, optim\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from torch.nn import CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !TODO: Random split 80/20 then 80>90/10\n",
    "# ! Metric: Accuracy, Precision, Recall, F1, AUC:\n",
    "# ! Accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
    "# ! Precision: TP / (TP + FP)\n",
    "# Macro average for equal class importance\n",
    "# ! AUC: discriminate between classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 354\u001b[0m\n\u001b[1;32m    351\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43mperform_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m    365\u001b[0m test_model(testloader, model, device)\n",
      "Cell \u001b[0;32mIn[1], line 247\u001b[0m, in \u001b[0;36mperform_training\u001b[0;34m(data, labels, vision_model, model_optimizer, loss_function, device, num_epochs, sampling_method)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_training\u001b[39m(\n\u001b[1;32m    238\u001b[0m     data,\n\u001b[1;32m    239\u001b[0m     labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     sampling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     train_data, train_labels, val_data, val_labels, test_data, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mTensorDataset(train_data, train_labels)\n\u001b[1;32m    252\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 220\u001b[0m, in \u001b[0;36msplit_data\u001b[0;34m(data, labels, dev_ratio, val_ratio)\u001b[0m\n\u001b[1;32m    217\u001b[0m dev_indices \u001b[38;5;241m=\u001b[39m indices[:num_dev]\n\u001b[1;32m    218\u001b[0m test_indices \u001b[38;5;241m=\u001b[39m indices[num_dev:]\n\u001b[0;32m--> 220\u001b[0m dev_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdev_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    221\u001b[0m dev_labels \u001b[38;5;241m=\u001b[39m labels[dev_indices]\n\u001b[1;32m    222\u001b[0m test_data \u001b[38;5;241m=\u001b[39m data[test_indices]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as activation_functions\n",
    "from torch.utils.data import default_collate\n",
    "import torch.nn as neural_network\n",
    "import torch.optim as optimization\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vit_b_32, ViT_B_32_Weights\n",
    "from torch import nn, optim\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# ------------------------- STEP 1: Set up environment\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(32)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Augmentation class\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MixUp:\n",
    "    \"\"\"\n",
    "    MixUp Data Augmentation Class\n",
    "\n",
    "    MixUp performs data augmentation by creating convex combinations of pairs of images and their labels,\n",
    "    improving model generalization by encouraging linear behavior in-between training examples.\n",
    "\n",
    "    Attributes:\n",
    "    - mix_sampling_method (int): Determines the method for sampling the MixUp parameter 位.\n",
    "        - 1: Sample 位 from a Beta distribution with parameters (alpha, alpha).\n",
    "        - 2: Sample 位 uniformly from the range specified in 'uniform_range'.\n",
    "    - alpha (float): The alpha parameter for the Beta distribution, relevant when mix_sampling_method is 1.\n",
    "    - uniform_range (tuple of float): The range from which 位 is uniformly sampled, relevant when mix_sampling_method is 2.\n",
    "    - num_classes (int): The number of classes in the dataset, used for one-hot encoding the labels.\n",
    "\n",
    "    Methods:\n",
    "    - __call__(images, labels): Applies MixUp augmentation to a batch of images and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, mix_sampling_method=1, alpha=0.2, uniform_range=(0.0, 1.0), num_classes=10\n",
    "    ):\n",
    "        self.mix_sampling_method = mix_sampling_method\n",
    "        self.alpha = alpha\n",
    "        self.uniform_range = uniform_range\n",
    "        self.num_classes = num_classes\n",
    "        # Ensure reproducibility\n",
    "        np.random.seed(42)  #! A ENLEVER\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "    def __call__(self, images, labels):\n",
    "        \"\"\"\n",
    "        Apply MixUp augmentation to a batch of images and labels.\n",
    "\n",
    "        Parameters:\n",
    "        - images (Tensor): A batch of images.\n",
    "        - labels (Tensor): Corresponding labels for the batch of images.\n",
    "\n",
    "        Returns:\n",
    "        - mixed_images (Tensor): Augmented images after applying MixUp.\n",
    "        - mixed_labels (Tensor): Augmented labels after applying MixUp.\n",
    "        \"\"\"\n",
    "        batch_size = images.size(0)\n",
    "        # Generate MixUp lambda parameter based on the specified sampling method\n",
    "        if self.mix_sampling_method == 1:\n",
    "            lam = np.random.beta(self.alpha, self.alpha, size=batch_size)\n",
    "        else:  # uniform sampling\n",
    "            lam = np.random.uniform(\n",
    "                self.uniform_range[0], self.uniform_range[1], size=batch_size\n",
    "            )\n",
    "\n",
    "        lam = torch.from_numpy(lam).float().to(images.device)\n",
    "        lam = lam.view(batch_size, 1, 1, 1)\n",
    "        index = torch.randperm(batch_size).to(images.device)\n",
    "\n",
    "        mixed_images = lam * images + (1 - lam) * images[index, :]\n",
    "        mixed_labels = self._mix_labels(labels, index, lam[:, 0, 0, 0])\n",
    "\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    def _mix_labels(self, labels, index, lam):\n",
    "        \"\"\"\n",
    "        Mix labels using the same lambda parameter used for mixing images.\n",
    "\n",
    "        Parameters:\n",
    "        - labels (Tensor): A batch of labels.\n",
    "        - index (Tensor): A tensor of shuffled indices.\n",
    "        - lam (Tensor): The lambda parameter used for mixing.\n",
    "\n",
    "        Returns:\n",
    "        - mixed_labels (Tensor): A tensor of mixed labels.\n",
    "        \"\"\"\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=self.num_classes).float()\n",
    "        return (\n",
    "            lam.view(-1, 1) * one_hot_labels\n",
    "            + (1 - lam.view(-1, 1)) * one_hot_labels[index]\n",
    "        )\n",
    "\n",
    "\n",
    "# Function for saving example images\n",
    "def save_sample_images(\n",
    "    image_transform,\n",
    "    dataset_loader,\n",
    "    category_names,\n",
    "    save_directory,\n",
    "    prediction_model=None,\n",
    "    sample_count=16,\n",
    "):\n",
    "    # ------------------------- STEP 2: Prepare data for visualization\n",
    "    data_iterator = iter(dataset_loader)\n",
    "    x_batch, y_batch = next(data_iterator)\n",
    "    while len(x_batch) < sample_count:\n",
    "        extra_x, extra_y = next(data_iterator)\n",
    "        x_batch = torch.cat((x_batch, extra_x), dim=0)\n",
    "        y_batch = torch.cat((y_batch, extra_y), dim=0)\n",
    "\n",
    "    # --------------------------------------- Substep 2.1: Perform prediction if a model is provided\n",
    "    if prediction_model is not None:\n",
    "        model_outputs = prediction_model(x_batch)\n",
    "        _, predictions = torch.max(model_outputs, 1)\n",
    "        true_labels = [category_names[label] for label in y_batch]\n",
    "        predicted_labels = [category_names[label] for label in predictions]\n",
    "\n",
    "    mean_values = torch.tensor(image_transform.mean).view(3, 1, 1)\n",
    "    std_values = torch.tensor(image_transform.std).view(3, 1, 1)\n",
    "\n",
    "    image_width = x_batch[0].shape[1]\n",
    "    image_height = x_batch[0].shape[2]\n",
    "    grid_columns = 6\n",
    "    grid_rows = sample_count // grid_columns + (1 if sample_count % grid_columns else 0)\n",
    "    image_grid = Image.new(\n",
    "        \"RGB\", (image_width * grid_columns, image_height * grid_rows), color=\"white\"\n",
    "    )\n",
    "\n",
    "    # ------------------------- STEP 3: Visualize and save images\n",
    "    for i in range(sample_count):\n",
    "        image_data = (x_batch[i] * std_values + mean_values).numpy()\n",
    "        image_data = np.transpose(image_data, (1, 2, 0))\n",
    "        img = Image.fromarray((image_data * 255).astype(np.uint8))\n",
    "\n",
    "        # --------------------------------------- Substep 3.1: Annotate images with labels or predictions\n",
    "        if prediction_model is None:\n",
    "            label_list = [\n",
    "                category_names[idx] + \":\" + str(round(y_batch[i][idx].item(), 2))\n",
    "                for idx in y_batch[i].nonzero()\n",
    "            ]\n",
    "            img_title = f\"{', '.join(label_list)}\"\n",
    "        else:\n",
    "            img_title = f\"GT: {true_labels[i]}\\nPred: {predicted_labels[i]}\"\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((10, 10), img_title, fill=\"white\")\n",
    "\n",
    "        # --------------------------------------- Substep 3.2: Compile images into a grid\n",
    "        row_num, col_num = divmod(i, grid_columns)\n",
    "        image_grid.paste(img, (col_num * image_width, row_num * image_height))\n",
    "\n",
    "    # --------------------------------------- Substep 3.3: Save the grid image\n",
    "    if not os.getcwd().split(os.sep)[-1].startswith(\"task\"):\n",
    "        save_directory = \"task2/\" + save_directory\n",
    "    image_grid.save(save_directory)\n",
    "    print(f\"Image saved at {save_directory}\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "# Function for splitting the data into train, validation, and test sets\n",
    "def split_data(data, labels, dev_ratio=0.8, val_ratio=0.1):\n",
    "    num_samples = len(data)\n",
    "    num_dev = int(num_samples * dev_ratio)\n",
    "    num_val = int(num_dev * val_ratio)\n",
    "\n",
    "    indices = torch.randperm(num_samples).tolist()\n",
    "    dev_indices = indices[:num_dev]\n",
    "    test_indices = indices[num_dev:]\n",
    "\n",
    "    dev_data = data[dev_indices]\n",
    "    dev_labels = labels[dev_indices]\n",
    "    test_data = data[test_indices]\n",
    "    test_labels = labels[test_indices]\n",
    "\n",
    "    train_indices = dev_indices[:-num_val]\n",
    "    val_indices = dev_indices[-num_val:]\n",
    "\n",
    "    train_data = dev_data[:-num_val]\n",
    "    train_labels = dev_labels[:-num_val]\n",
    "    val_data = dev_data[-num_val:]\n",
    "    val_labels = dev_labels[-num_val:]\n",
    "\n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "# Function for splitting the data into train, validation, and test sets\n",
    "def split_data(data, labels, dev_ratio=0.8, val_ratio=0.1):\n",
    "    num_samples = len(data)\n",
    "    num_dev = int(num_samples * dev_ratio)\n",
    "    num_val = int(num_dev * val_ratio)\n",
    "\n",
    "    indices = torch.randperm(num_samples).tolist()\n",
    "    dev_indices = indices[:num_dev]\n",
    "    test_indices = indices[num_dev:]\n",
    "\n",
    "    dev_data = data[dev_indices]\n",
    "    dev_labels = labels[dev_indices]\n",
    "    test_data = data[test_indices]\n",
    "    test_labels = labels[test_indices]\n",
    "\n",
    "    train_indices = dev_indices[:-num_val]\n",
    "    val_indices = dev_indices[-num_val:]\n",
    "\n",
    "    train_data = dev_data[:-num_val]\n",
    "    train_labels = dev_labels[:-num_val]\n",
    "    val_data = dev_data[-num_val:]\n",
    "    val_labels = dev_labels[-num_val:]\n",
    "\n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "# Function for training the model\n",
    "def perform_training(\n",
    "    data,\n",
    "    labels,\n",
    "    vision_model,\n",
    "    model_optimizer,\n",
    "    loss_function,\n",
    "    device,\n",
    "    num_epochs=20,\n",
    "    sampling_method=1,\n",
    "):\n",
    "    train_data, train_labels, val_data, val_labels, test_data, test_labels = split_data(\n",
    "        data, labels\n",
    "    )\n",
    "\n",
    "    train_dataset = data.TensorDataset(train_data, train_labels)\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataset = data.TensorDataset(val_data, val_labels)\n",
    "    val_loader = data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    vision_model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_index, (x_input, y_label) in enumerate(train_loader, 0):\n",
    "            x_input, y_label = x_input.to(device), y_label.to(device)\n",
    "\n",
    "            # MixUp augmentation\n",
    "            mixup = MixUp(sampling_method)\n",
    "            mixed_x, mixed_y = mixup(x_input, y_label)\n",
    "\n",
    "            model_optimizer.zero_grad()\n",
    "\n",
    "            model_output = vision_model(mixed_x)\n",
    "            batch_loss = loss_function(model_output, mixed_y)\n",
    "            batch_loss.backward()\n",
    "            model_optimizer.step()\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1}, Training Loss: {total_loss / len(train_loader):.3f}\"\n",
    "        )\n",
    "\n",
    "        vision_model.eval()\n",
    "        val_predictions = []\n",
    "        val_labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                val_output = vision_model(x_val)\n",
    "                val_predictions.append(val_output)\n",
    "                val_labels_list.append(y_val)\n",
    "\n",
    "        val_predictions = torch.cat(val_predictions, dim=0)\n",
    "        val_labels = torch.cat(val_labels_list, dim=0)\n",
    "\n",
    "        val_auc = nn.functional.roc_auc_score(\n",
    "            val_predictions, val_labels, multi_class=\"ovr\"\n",
    "        )\n",
    "        val_accuracy = nn.functional.accuracy(val_predictions, val_labels)\n",
    "        print(\n",
    "            f\"Validation AUC-ROC: {val_auc:.3f}, Validation Accuracy: {val_accuracy:.3f}\"\n",
    "        )\n",
    "\n",
    "        vision_model.train()\n",
    "\n",
    "    torch.save(vision_model.state_dict(), f\"model_{sampling_method}.pth\")\n",
    "    print(\"Saved trained model\")\n",
    "\n",
    "\n",
    "def test_model(test_loader, vision_model, device):\n",
    "    vision_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vision_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy of the model on the test images: {accuracy}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Data loading and transformation\n",
    "    transform = ViT_B_32_Weights.IMAGENET1K_V1.transforms()\n",
    "    trainset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "    testset = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 20\n",
    "\n",
    "    for sampling_method in [1, 2]:\n",
    "\n",
    "        # MixUp initialization\n",
    "        mixup = MixUp(mix_sampling_method=sampling_method)\n",
    "\n",
    "        # Model setup\n",
    "        model = vit_b_32(weights=ViT_B_32_Weights.DEFAULT)\n",
    "        model.heads = nn.Sequential(\n",
    "            nn.Linear(model.heads[0].in_features, 10)\n",
    "        )  # Adjusting for CIFAR-10\n",
    "        model.to(device)\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "        # Training\n",
    "        perform_training(\n",
    "            trainloader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            device,\n",
    "            sampling_method,\n",
    "            num_epochs,\n",
    "        )\n",
    "\n",
    "        # Testing\n",
    "        test_model(testloader, model, device)\n",
    "        save_sample_images(\n",
    "            transform,\n",
    "            testloader,\n",
    "            category_names=[\n",
    "                \"plane\",\n",
    "                \"car\",\n",
    "                \"bird\",\n",
    "                \"cat\",\n",
    "                \"deer\",\n",
    "                \"dog\",\n",
    "                \"frog\",\n",
    "                \"horse\",\n",
    "                \"ship\",\n",
    "                \"truck\",\n",
    "            ],\n",
    "            save_directory=f\"result_{sampling_method}.png\",\n",
    "            prediction_model=model,\n",
    "            sample_count=36,\n",
    "        )\n",
    "\n",
    "        # Visualization\n",
    "        save_sample_images(\n",
    "            transform,\n",
    "            testloader,\n",
    "            [\n",
    "                \"plane\",\n",
    "                \"car\",\n",
    "                \"bird\",\n",
    "                \"cat\",\n",
    "                \"deer\",\n",
    "                \"dog\",\n",
    "                \"frog\",\n",
    "                \"horse\",\n",
    "                \"ship\",\n",
    "                \"truck\",\n",
    "            ],\n",
    "            \"result.png\",\n",
    "            model,\n",
    "            36,\n",
    "        )\n",
    "# Make sure to adjust the script as needed based on your specific setup, paths, and requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
