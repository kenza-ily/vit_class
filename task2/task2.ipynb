{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# ----------------- Importing Libraries  -------------------------------------\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Normalize, Resize\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "\n",
    "# ----------------- FIXED VALUES ------------------------------------\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MixUp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[1;32m     84\u001b[0m mixup \u001b[38;5;241m=\u001b[39m MixUp(sampling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, uni_range\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n\u001b[0;32m---> 85\u001b[0m \u001b[43mvisualize_mixup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 64\u001b[0m, in \u001b[0;36mvisualize_mixup\u001b[0;34m(mixup, dataloader, num_images)\u001b[0m\n\u001b[1;32m     61\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(RANDOM_SEED)\n\u001b[1;32m     63\u001b[0m mixed_x, images, mixed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\n\u001b[0;32m---> 64\u001b[0m mixed_images, mixed_labels \u001b[38;5;241m=\u001b[39m \u001b[43mmixup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixed_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Select a subset of images for visualization\u001b[39;00m\n\u001b[1;32m     67\u001b[0m mixed_images \u001b[38;5;241m=\u001b[39m mixed_images[:num_images]\n",
      "Cell \u001b[0;32mIn[41], line 26\u001b[0m, in \u001b[0;36mMixUp.__call__\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m mixed_x \u001b[38;5;241m=\u001b[39m lam \u001b[38;5;241m*\u001b[39m images \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lam) \u001b[38;5;241m*\u001b[39m images[index, :]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Convert labels to one-hot encoding and perform mixup\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m y_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     27\u001b[0m mixed_y \u001b[38;5;241m=\u001b[39m lam \u001b[38;5;241m*\u001b[39m y_one_hot \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lam) \u001b[38;5;241m*\u001b[39m y_one_hot[index]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixed_x, mixed_y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "# ------------------------------ MIXUP / Define MixUp class ------------------------------\n",
    "class MixUp(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sampling_method: int = 1,\n",
    "        num_classes: int = 10,\n",
    "        alpha: float = 1.0,\n",
    "        uni_range: list = [0.0, 1.0],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sampling_method = sampling_method\n",
    "        self.num_classes = num_classes\n",
    "        self.alpha = alpha\n",
    "        self.uni_range = uni_range\n",
    "\n",
    "    def __call__(self, images, labels):\n",
    "        # Set random seeds for reproducibility\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "        # Sample lambda for mixup based on the specified sampling method\n",
    "        if self.sampling_method == 1:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "        elif self.sampling_method == 2:\n",
    "            lam = np.random.uniform(self.uni_range[0], self.uni_range[1])\n",
    "\n",
    "        # Perform mixup on images\n",
    "        index = torch.randperm(images.size(0))\n",
    "        mixed_x = lam * images + (1 - lam) * images[index, :]\n",
    "\n",
    "        # Convert labels to one-hot encoding and perform mixup\n",
    "        y_one_hot = F.one_hot(labels, num_classes=self.num_classes).float()\n",
    "        mixed_y = lam * y_one_hot + (1 - lam) * y_one_hot[index]\n",
    "\n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "\n",
    "# Custom collate function that applies MixUp and retains original images\n",
    "def collate_fn(batch):\n",
    "    batch = default_collate(batch)\n",
    "    images, labels = batch\n",
    "    mixup = MixUp(sampling_method=1, num_classes=10, alpha=1.0, uni_range=[0.0, 1.0])\n",
    "    mixed_x, mixed_y = mixup(images, labels)\n",
    "    return mixed_x, images, mixed_y\n",
    "\n",
    "\n",
    "# Data transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        Resize((224, 224)),  # Resize images to fit the input size expected by MixUp\n",
    "        ToTensor(),\n",
    "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# CIFAR-10 training dataset and DataLoader\n",
    "trainset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=32, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "# Visualization function\n",
    "def visualize_mixup(mixup, dataloader, num_images=16):\n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    mixed_x, images, mixed_y = next(iter(dataloader))\n",
    "    mixed_images, mixed_labels = mixup(images, mixed_y)\n",
    "\n",
    "    # Select a subset of images for visualization\n",
    "    mixed_images = mixed_images[:num_images]\n",
    "\n",
    "    # Create a grid of images\n",
    "    grid = make_grid(mixed_images, nrow=int(np.sqrt(num_images)))\n",
    "    ndarr = (\n",
    "        grid.mul(255)\n",
    "        .add_(0.5)\n",
    "        .clamp_(0, 255)\n",
    "        .permute(1, 2, 0)\n",
    "        .to(\"cpu\", torch.uint8)\n",
    "        .numpy()\n",
    "    )\n",
    "    img = Image.fromarray(ndarr)\n",
    "    img.save(\"mixup.png\")\n",
    "\n",
    "\n",
    "# Usage example\n",
    "mixup = MixUp(sampling_method=1, num_classes=10, alpha=1.0, uni_range=[0.0, 1.0])\n",
    "visualize_mixup(mixup, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Usage example, assuming 'dataloader' is defined and provides CIFAR-10 or similar images\u001b[39;00m\n\u001b[1;32m     81\u001b[0m mixup \u001b[38;5;241m=\u001b[39m MixUp(sampling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, uni_range\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n\u001b[0;32m---> 82\u001b[0m \u001b[43mvisualize_mixup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 60\u001b[0m, in \u001b[0;36mvisualize_mixup\u001b[0;34m(mixup, dataloader, num_images)\u001b[0m\n\u001b[1;32m     57\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(RANDOM_SEED)\n\u001b[1;32m     58\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(RANDOM_SEED)\n\u001b[0;32m---> 60\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m mixed_images, mixed_labels \u001b[38;5;241m=\u001b[39m mixup(images, labels)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Select a subset of images for visualization\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/comp0197-cw1-pt/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/comp0197-cw1-pt/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/comp0197-cw1-pt/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m batch \u001b[38;5;241m=\u001b[39m default_collate(batch)\n\u001b[1;32m      7\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m----> 8\u001b[0m mixup_images, labels_a, labels_b, lam \u001b[38;5;241m=\u001b[39m mixup(images, labels)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     mixup_images,\n\u001b[1;32m     11\u001b[0m     images,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     lam,\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# Define the MixUp class here (as previously discussed)\n",
    "\n",
    "\n",
    "# # Visualization of MixUp-augmented and original images\n",
    "# mixup.visualize(trainloader, num_images=16)\n",
    "\n",
    "# import torchvision\n",
    "# import numpy as np\n",
    "# from torchvision.utils import make_grid\n",
    "# from PIL import Image\n",
    "\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "# import torchvision\n",
    "# import numpy as np\n",
    "# from torchvision.utils import make_grid\n",
    "# from PIL import Image\n",
    "\n",
    "# RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Usage example, assuming 'dataloader' is defined and provides CIFAR-10 or similar images\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mixup \u001b[38;5;241m=\u001b[39m MixUp(sampling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, uni_range\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvisualize_mixup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 60\u001b[0m, in \u001b[0;36mvisualize_mixup\u001b[0;34m(mixup, dataloader, num_images)\u001b[0m\n\u001b[1;32m     57\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(RANDOM_SEED)\n\u001b[1;32m     58\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(RANDOM_SEED)\n\u001b[0;32m---> 60\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m mixed_images, mixed_labels \u001b[38;5;241m=\u001b[39m mixup(images, labels)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Select a subset of images for visualization\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/comp0197-cw1-pt/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/comp0197-cw1-pt/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/comp0197-cw1-pt/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 52\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     50\u001b[0m mixup \u001b[38;5;241m=\u001b[39m MixUp(sampling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, uni_range\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n\u001b[1;32m     51\u001b[0m mixed_x, mixed_y \u001b[38;5;241m=\u001b[39m mixup(images, labels)\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixed_x, images, mixed_y, \u001b[43mlam\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lam' is not defined"
     ]
    }
   ],
   "source": [
    "# Usage example, assuming 'dataloader' is defined and provides CIFAR-10 or similar images\n",
    "mixup = MixUp(sampling_method=1, num_classes=10, alpha=1.0, uni_range=[0.0, 1.0])\n",
    "visualize_mixup(mixup, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Montage of augmented images saved to 'mixup.png'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vit_b_32\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.vit = vit_b_32(pretrained=True)\n",
    "\n",
    "        # Freeze all layers in the pretrained model\n",
    "        for param in self.vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the head with a new linear layer\n",
    "        self.vit.heads.head = nn.Linear(self.vit.heads.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision.transforms import Resize\n",
    "from models import ViT\n",
    "from data import MixUp\n",
    "\n",
    "PRUNING_AMOUNT = 0.1\n",
    "\n",
    "\n",
    "def apply_pruning(module, amount=PRUNING_AMOUNT):\n",
    "    \"\"\"Apply unstructured pruning based on the L1 norm of weights.\"\"\"\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            prune.l1_unstructured(m, name=\"weight\", amount=amount)\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "def train_with_mixup(sampling_method, num_epochs=20):\n",
    "\n",
    "    # Defining the data transformation for CIFAR-10\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "            transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "            transforms.Normalize(\n",
    "                (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "            ),  # Normalize the images\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Load the CIFAR-10 dataset - train and test\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=\"data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=\"data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Define the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    # Ensure the SimplifiedViT class is correctly initialized as per your modifications\n",
    "    net = ViT().to(device)\n",
    "    net.vit.heads.head.apply(initialize_weights)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(\n",
    "        net.parameters(), lr=0.01, momentum=0.9\n",
    "    )  # v2 - lr=0.001 brought very low results with SimplifiedViT v1 -> lr=0.01\n",
    "    mixup = MixUp(alpha=1.0, sampling_method=sampling_method, seed=42)\n",
    "\n",
    "    # v2 - Introduce a learning rate scheduler\n",
    "    scheduler = lr_scheduler.StepLR(\n",
    "        optimizer, step_size=5, gamma=0.1\n",
    "    )  # Adjust learning rate every 5 epochs\n",
    "\n",
    "    train_acc, test_acc = [], []  # Initialize accuracy lists\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        # Training loop\n",
    "        net.train()  # Set the model to training mode\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs, targets_a, targets_b, lam = mixup(inputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the predicted labels\n",
    "            total += labels.size(0)\n",
    "            correct += (\n",
    "                (\n",
    "                    lam * (predicted == targets_a).float()\n",
    "                    + (1 - lam) * (predicted == targets_b).float()\n",
    "                )\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "\n",
    "        # v4 - Prunning\n",
    "        # Apply pruning at specified epochs and gradually increase the amount\n",
    "        if epoch % 5 == 4:  # Example: Apply pruning every 5 epochs\n",
    "            prune_amount = 0.05 + 0.05 * (\n",
    "                epoch // 5\n",
    "            )  # Increase pruning amount gradually\n",
    "            apply_pruning(net, amount=prune_amount)\n",
    "            print(f\"Applied pruning with amount {prune_amount:.2f}\")\n",
    "\n",
    "        # v2 - Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        train_acc.append(100 * correct / total)\n",
    "        print(f\"Epoch {epoch+1} - Training accuracy: {train_acc[-1]:.2f}%\")\n",
    "\n",
    "        # Test loop\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc.append(100 * correct / total)\n",
    "        print(f\"Epoch {epoch+1} - Test accuracy: {test_acc[-1]:.2f}%\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_path = os.path.join(\".\", f\"model_sampling_{sampling_method}.pth\")\n",
    "    torch.save(net.state_dict(), model_path)\n",
    "    print(f\"Model with sampling method {sampling_method} saved to {model_path}\")\n",
    "\n",
    "    return train_acc, test_acc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Training with sampling method 1 (beta distribution)\")\n",
    "    train_acc_1, test_acc_1 = train_with_mixup(sampling_method=1)\n",
    "\n",
    "    print(\"Training with sampling method 2 (uniform distribution)\")\n",
    "    train_acc_2, test_acc_2 = train_with_mixup(sampling_method=2)\n",
    "\n",
    "    # Report test set performance\n",
    "    print(\"Test set performance for sampling method 1:\")\n",
    "    for epoch, acc in enumerate(test_acc_1):\n",
    "        print(f\"Epoch {epoch+1} - Test accuracy: {acc:.2f}%\")\n",
    "\n",
    "    print(\"Test set performance for sampling method 2:\")\n",
    "    for epoch, acc in enumerate(test_acc_2):\n",
    "        print(f\"Epoch {epoch+1} - Test accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from models import ViT\n",
    "\n",
    "\n",
    "def visualize_results(model_path, testloader, classes, num_images=36):\n",
    "    # Load the trained model\n",
    "    net = ViT()\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    net.eval()\n",
    "\n",
    "    # Get a batch of test images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    # Make predictions on the test images\n",
    "    images = images.cuda()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Create a montage of the test images with labels\n",
    "    montage = make_grid(images[:num_images], nrow=6, padding=2).cpu()\n",
    "    montage_image = transforms.ToPILImage()(montage)\n",
    "\n",
    "    # Add labels to the montage\n",
    "    draw = ImageDraw.Draw(montage_image)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 12)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        x = i % 6 * montage_image.width // 6 + 5\n",
    "        y = i // 6 * montage_image.height // 6 + 5\n",
    "        label_text = f\"Truth: {classes[labels[i]]}\\nPredicted: {classes[predicted[i]]}\"\n",
    "        draw.text((x, y), label_text, font=font, fill=\"black\")\n",
    "\n",
    "    # Save the montage as \"result.png\"\n",
    "    result_path = os.path.join(os.path.dirname(model_path), \"result.png\")\n",
    "    montage_image.save(result_path)\n",
    "    print(f\"Montage of test images with labels saved to {result_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
