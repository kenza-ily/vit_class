{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab adapted to ViT instead of CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixup ago\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tqdm -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# #!/usr/bin/env python3 -u\n",
    "# # Copyright (c) 2017-present, Facebook, Inc.\n",
    "# # All rights reserved.\n",
    "# #\n",
    "# # This source code is licensed under the license found in the LICENSE file in\n",
    "# # the root directory of this source tree.\n",
    "# from __future__ import print_function\n",
    "\n",
    "# import argparse\n",
    "# import csv\n",
    "# import os\n",
    "# from torchvision.transforms import Resize\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.autograd import Variable\n",
    "# import torch.backends.cudnn as cudnn\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "# import models\n",
    "\n",
    "\n",
    "# import argparse\n",
    "\n",
    "\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(description=\"PyTorch CIFAR10 Training with ViT\")\n",
    "#     parser.add_argument(\"--lr\", default=0.1, type=float, help=\"learning rate\")\n",
    "#     parser.add_argument(\n",
    "#         \"--resume\", \"-r\", action=\"store_true\", help=\"resume from checkpoint\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--model\",\n",
    "#         default=\"vit_small_patch16_224\",\n",
    "#         type=str,\n",
    "#         help=\"model type (default: vit_small_patch16_224)\",\n",
    "#     )\n",
    "#     parser.add_argument(\"--name\", default=\"0\", type=str, help=\"name of run\")\n",
    "#     parser.add_argument(\"--seed\", default=0, type=int, help=\"random seed\")\n",
    "#     parser.add_argument(\"--batch-size\", default=128, type=int, help=\"batch size\")\n",
    "#     parser.add_argument(\"--epoch\", default=200, type=int, help=\"total epochs to run\")\n",
    "#     parser.add_argument(\n",
    "#         \"--no-augment\",\n",
    "#         dest=\"augment\",\n",
    "#         action=\"store_false\",\n",
    "#         help=\"use standard augmentation (default: True)\",\n",
    "#     )\n",
    "#     parser.add_argument(\"--decay\", default=1e-4, type=float, help=\"weight decay\")\n",
    "#     parser.add_argument(\n",
    "#         \"--alpha\",\n",
    "#         default=1.0,\n",
    "#         type=float,\n",
    "#         help=\"mixup interpolation coefficient (default: 1)\",\n",
    "#     )\n",
    "\n",
    "#     # Use parse_known_args to ignore unrecognized command line arguments\n",
    "#     args, _ = parser.parse_known_args()\n",
    "#     return args\n",
    "\n",
    "\n",
    "# # Use this function where you initialize your training setup\n",
    "# args = parse_args()\n",
    "\n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# best_acc = 0  # best test accuracy\n",
    "# start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# if args.seed != 0:\n",
    "#     torch.manual_seed(args.seed)\n",
    "\n",
    "# # Data\n",
    "# print(\"==> Preparing data..\")\n",
    "# if args.augment:\n",
    "#     transform_train = transforms.Compose([\n",
    "#         Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "#         transforms.RandomCrop(32, padding=4),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "#     ])\n",
    "# else:\n",
    "#     transform_train = transforms.Compose([\n",
    "#         Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "#     ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "\n",
    "# trainset = datasets.CIFAR10(\n",
    "#     root=\"~/data\", train=True, download=False, transform=transform_train\n",
    "# )\n",
    "# trainloader = torch.utils.data.DataLoader(\n",
    "#     trainset, batch_size=args.batch_size, shuffle=True, num_workers=8\n",
    "# )\n",
    "\n",
    "# testset = datasets.CIFAR10(\n",
    "#     root=\"~/data\", train=False, download=False, transform=transform_test\n",
    "# )\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     testset, batch_size=100, shuffle=False, num_workers=8\n",
    "# )\n",
    "\n",
    "\n",
    "# # Model\n",
    "# if args.resume:\n",
    "#     # Load checkpoint.\n",
    "#     print(\"==> Resuming from checkpoint..\")\n",
    "#     assert os.path.isdir(\"checkpoint\"), \"Error: no checkpoint directory found!\"\n",
    "#     checkpoint = torch.load(\"./checkpoint/ckpt.t7\" + args.name + \"_\" + str(args.seed))\n",
    "#     net = checkpoint[\"net\"]\n",
    "#     best_acc = checkpoint[\"acc\"]\n",
    "#     start_epoch = checkpoint[\"epoch\"] + 1\n",
    "#     rng_state = checkpoint[\"rng_state\"]\n",
    "#     torch.set_rng_state(rng_state)\n",
    "# else:\n",
    "#     print(\"==> Building model..\")\n",
    "#     net = models.__dict__[args.model]()\n",
    "\n",
    "# if not os.path.isdir(\"results\"):\n",
    "#     os.mkdir(\"results\")\n",
    "# logname = (\n",
    "#     \"results/log_\"\n",
    "#     + net.__class__.__name__\n",
    "#     + \"_\"\n",
    "#     + args.name\n",
    "#     + \"_\"\n",
    "#     + str(args.seed)\n",
    "#     + \".csv\"\n",
    "# )\n",
    "\n",
    "# if use_cuda:\n",
    "#     net.cuda()\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     print(torch.cuda.device_count())\n",
    "#     cudnn.benchmark = True\n",
    "#     print(\"Using CUDA..\")\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(\n",
    "#     net.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.decay\n",
    "# )\n",
    "\n",
    "\n",
    "# def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "#     \"\"\"Returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "#     if alpha > 0:\n",
    "#         lam = np.random.beta(alpha, alpha)\n",
    "#     else:\n",
    "#         lam = 1\n",
    "\n",
    "#     batch_size = x.size()[0]\n",
    "#     if use_cuda:\n",
    "#         index = torch.randperm(batch_size).cuda()\n",
    "#     else:\n",
    "#         index = torch.randperm(batch_size)\n",
    "\n",
    "#     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "#     y_a, y_b = y, y[index]\n",
    "#     return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "# def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "#     return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# def train(epoch):\n",
    "#     print(\"\\nEpoch: %d\" % epoch)\n",
    "#     net.train()\n",
    "#     train_loss = 0\n",
    "#     reg_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "#         if use_cuda:\n",
    "#             inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "#         inputs, targets_a, targets_b, lam = mixup_data(\n",
    "#             inputs, targets, args.alpha, use_cuda\n",
    "#         )\n",
    "#         inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\n",
    "#         outputs = net(inputs)\n",
    "#         loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "#         train_loss += loss.data[0]\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += targets.size(0)\n",
    "#         correct += (\n",
    "#             lam * predicted.eq(targets_a.data).cpu().sum().float()\n",
    "#             + (1 - lam) * predicted.eq(targets_b.data).cpu().sum().float()\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         print(\n",
    "#             \"Batch: %d/%d | Loss: %.3f | Reg: %.5f | Acc: %.3f%% (%d/%d)\"\n",
    "#             % (\n",
    "#                 batch_idx + 1,\n",
    "#                 len(trainloader),\n",
    "#                 train_loss / (batch_idx + 1),\n",
    "#                 reg_loss / (batch_idx + 1),\n",
    "#                 100.0 * correct / total,\n",
    "#                 correct,\n",
    "#                 total,\n",
    "#             )\n",
    "#         )\n",
    "#     return (train_loss / batch_idx, reg_loss / batch_idx, 100.0 * correct / total)\n",
    "\n",
    "\n",
    "# def test(epoch):\n",
    "#     global best_acc\n",
    "#     net.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "#         if use_cuda:\n",
    "#             inputs, targets = inputs.cuda(), targets.cuda()\n",
    "#         inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "#         test_loss += loss.data[0]\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "#         print(\"acc =\", acc)\n",
    "#         if epoch == start_epoch + args.epoch - 1 or acc > best_acc:\n",
    "#             print(\"Saving..\")\n",
    "#         if acc > best_acc:\n",
    "#             print(\"best_acc =\", best_acc)\n",
    "#         print(\"test_loss =\", test_loss / batch_idx)\n",
    "#         print(\"correct =\", 100.0 * correct / total)\n",
    "#     acc = 100.0 * correct / total\n",
    "#     if epoch == start_epoch + args.epoch - 1 or acc > best_acc:\n",
    "#         checkpoint(acc, epoch)\n",
    "#     if acc > best_acc:\n",
    "#         best_acc = acc\n",
    "#     return (test_loss / batch_idx, 100.0 * correct / total)\n",
    "\n",
    "\n",
    "# def checkpoint(acc, epoch):\n",
    "#     # Save checkpoint.\n",
    "#     print(\"Saving..\")\n",
    "#     state = {\"net\": net, \"acc\": acc, \"epoch\": epoch, \"rng_state\": torch.get_rng_state()}\n",
    "#     if not os.path.isdir(\"checkpoint\"):\n",
    "#         os.mkdir(\"checkpoint\")\n",
    "#     torch.save(state, \"./checkpoint/ckpt.t7\" + args.name + \"_\" + str(args.seed))\n",
    "\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch):\n",
    "#     \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
    "#     lr = args.lr\n",
    "#     if epoch >= 100:\n",
    "#         lr /= 10\n",
    "#     if epoch >= 150:\n",
    "#         lr /= 10\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "# if not os.path.exists(logname):\n",
    "#     with open(logname, \"w\") as logfile:\n",
    "#         logwriter = csv.writer(logfile, delimiter=\",\")\n",
    "#         logwriter.writerow(\n",
    "#             [\"epoch\", \"train loss\", \"reg loss\", \"train acc\", \"test loss\", \"test acc\"]\n",
    "#         )\n",
    "\n",
    "# for epoch in range(start_epoch, args.epoch):\n",
    "#     train_loss, reg_loss, train_acc = train(epoch)\n",
    "#     test_loss, test_acc = test(epoch)\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     with open(logname, \"a\") as logfile:\n",
    "#         logwriter = csv.writer(logfile, delimiter=\",\")\n",
    "#         logwriter.writerow(\n",
    "#             [epoch, train_loss, reg_loss, train_acc, test_loss, test_acc]\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "train_pt_images.jpg saved.\n",
      "Ground truth labels:  car  bird plane  deer truck   cat   dog horse plane  deer   car truck   car   car   car horse  deer truck  frog  ship\n",
      "[1, 200] loss: 1.373\n",
      "[1, 400] loss: 1.102\n",
      "[1, 600] loss: 1.035\n",
      "[1, 800] loss: 1.055\n",
      "[1, 1000] loss: 1.038\n",
      "[1, 1200] loss: 1.033\n",
      "[1, 1400] loss: 0.982\n",
      "[1, 1600] loss: 0.980\n",
      "[1, 1800] loss: 0.970\n",
      "[1, 2000] loss: 0.953\n",
      "[1, 2200] loss: 0.982\n",
      "[1, 2400] loss: 0.952\n",
      "[2, 200] loss: 0.887\n",
      "[2, 400] loss: 0.912\n",
      "[2, 600] loss: 0.940\n",
      "[2, 800] loss: 0.970\n",
      "[2, 1000] loss: 0.953\n",
      "[2, 1200] loss: 0.908\n",
      "[2, 1400] loss: 0.914\n",
      "[2, 1600] loss: 0.888\n",
      "[2, 1800] loss: 0.941\n",
      "[2, 2000] loss: 0.895\n",
      "[2, 2200] loss: 0.908\n",
      "[2, 2400] loss: 0.875\n",
      "Training done.\n",
      "Model with mixup saved.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "# -------------- ViT --------------\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transformer = models.vit_b_16(pretrained=True)\n",
    "        self.fc = nn.Linear(\n",
    "            1000, 10\n",
    "        )  # Assuming the output features from vit_b_32 are 1000\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ------------- Mixup data -------------\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    \"\"\"Returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "# -------------- Mixup criterion --------------\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# -------------- Training --------------\n",
    "if __name__ == \"__main__\":\n",
    "    ## Prepare the CIFAR-10 dataset\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    batch_size = 20\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    classes = (\n",
    "        \"plane\",\n",
    "        \"car\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    )\n",
    "\n",
    "    # TODO: Generate example images for visualization\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    im = Image.fromarray(\n",
    "        (torch.cat(images.split(1, 0), 3).squeeze() / 2 * 255 + 0.5 * 255)\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "        .astype(\"uint8\")\n",
    "    )\n",
    "    im.save(\"train_pt_images.jpg\")\n",
    "    print(\"train_pt_images.jpg saved.\")\n",
    "    print(\n",
    "        \"Ground truth labels:\"\n",
    "        + \" \".join(\"%5s\" % classes[labels[j]] for j in range(batch_size))\n",
    "    )\n",
    "\n",
    "    ## Initialize the ViT model\n",
    "    net = Net()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    ## Set the loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    ## Train the model with Mixup augmentation\n",
    "    alpha = 1.0  # Mixup interpolation coefficient, adjust as needed\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # TODO: Apply Mixup augmentation\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(\n",
    "                inputs, labels, alpha, use_cuda\n",
    "            )\n",
    "            inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "\n",
    "            # TODO: Perform backpropagation and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # TODO: Log training progress\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:  # print every 200 mini-batches\n",
    "                print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print(\"Training done.\")\n",
    "\n",
    "    # TODO: Save the trained model\n",
    "    torch.save(net.state_dict(), \"saved_model_with_mixup.pt\")\n",
    "    print(\"Model with mixup saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1, 200] loss: 1.327\n",
      "[1, 400] loss: 1.081\n",
      "[1, 600] loss: 1.050\n",
      "[1, 800] loss: 1.012\n",
      "[1, 1000] loss: 1.035\n",
      "[1, 1200] loss: 1.026\n",
      "[1, 1400] loss: 1.031\n",
      "[1, 1600] loss: 1.012\n",
      "[1, 1800] loss: 0.951\n",
      "[1, 2000] loss: 0.982\n",
      "[1, 2200] loss: 0.955\n",
      "[1, 2400] loss: 0.978\n",
      "[2, 200] loss: 0.912\n",
      "[2, 400] loss: 0.919\n",
      "[2, 600] loss: 0.966\n",
      "[2, 800] loss: 0.961\n",
      "[2, 1000] loss: 0.932\n",
      "[2, 1200] loss: 0.907\n",
      "[2, 1400] loss: 0.867\n",
      "[2, 1600] loss: 0.898\n",
      "[2, 1800] loss: 0.890\n",
      "[2, 2000] loss: 0.905\n",
      "[2, 2200] loss: 0.916\n",
      "[2, 2400] loss: 0.897\n",
      "Training done.\n",
      "Montage of augmented images saved to 'mixup.png'\n",
      "Model with mixup saved.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "\n",
    "# -------------- ViT --------------\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transformer = models.vit_b_32(pretrained=True)\n",
    "        self.fc = nn.Linear(\n",
    "            1000, 10\n",
    "        )  # Assuming the output features from vit_b_32 are 1000\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------- MixUp --------------\n",
    "class MixUp(object):\n",
    "    def __init__(self, alpha=1.0, sampling_method=1, seed=42):\n",
    "        self.alpha = alpha\n",
    "        self.sampling_method = sampling_method\n",
    "        self.seed = seed\n",
    "        self.torch_rng = torch.manual_seed(seed)\n",
    "        self.np_rng = np.random.seed(seed)\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        if self.sampling_method == 1:\n",
    "            lam = self.get_lambda_beta()\n",
    "        else:\n",
    "            lam = self.get_lambda_uniform()\n",
    "\n",
    "        batch_size = x.size()[0]\n",
    "        if self.use_cuda:\n",
    "            index = torch.randperm(batch_size).cuda()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        else:\n",
    "            index = torch.randperm(batch_size)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "\n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "    def get_lambda_beta(self):\n",
    "        return np.random.beta(self.alpha, self.alpha)\n",
    "\n",
    "    def get_lambda_uniform(self):\n",
    "        return np.random.uniform(0, 1)\n",
    "\n",
    "    def visualize(self, dataloader, num_images=16):\n",
    "        dataiter = iter(dataloader)\n",
    "        images, labels = next(dataiter)\n",
    "\n",
    "        mixed_images = []\n",
    "        for i in range(num_images):\n",
    "            mixed_x, _, _, _ = self.__call__(images, labels)\n",
    "            mixed_images.append(mixed_x[i])\n",
    "\n",
    "        montage = transforms.Resize((224, 224))(\n",
    "            torchvision.utils.make_grid(torch.stack(mixed_images), nrow=4)\n",
    "        )\n",
    "        montage = montage.permute(1, 2, 0).numpy() * 255\n",
    "        image = Image.fromarray(montage.astype(\"uint8\"))\n",
    "        image.save(\"mixup.png\")\n",
    "        print(\"Montage of augmented images saved to 'mixup.png'\")\n",
    "\n",
    "\n",
    "# ------------- Mixup criterion --------------\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# -------------- Training --------------\n",
    "if __name__ == \"__main__\":\n",
    "    ## Prepare the CIFAR-10 dataset\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    batch_size = 20\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    classes = (\n",
    "        \"plane\",\n",
    "        \"car\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    )\n",
    "\n",
    "    ## Initialize the ViT model\n",
    "    net = ViT()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    ## Set the loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    ## Initialize MixUp\n",
    "    mixup = MixUp(alpha=1.0, sampling_method=1, seed=42)\n",
    "\n",
    "    ## Train the model with Mixup augmentation\n",
    "    alpha = 1.0  # Mixup interpolation coefficient, adjust as needed\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Apply Mixup augmentation\n",
    "            inputs, targets_a, targets_b, lam = mixup(inputs, labels)\n",
    "            inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets_a, targets_b = (\n",
    "                    inputs.cuda(),\n",
    "                    targets_a.cuda(),\n",
    "                    targets_b.cuda(),\n",
    "                )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:\n",
    "                print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print(\"Training done.\")\n",
    "\n",
    "    # Visualize augmented images\n",
    "    mixup.visualize(trainloader)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(net.state_dict(), \"saved_model_with_mixup.pt\")\n",
    "    print(\"Model with mixup saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
